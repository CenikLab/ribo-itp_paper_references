{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e53ba4",
   "metadata": {},
   "source": [
    "# Removing MTRN2Ls from Human Refrence\n",
    "\n",
    "We are going to remove the following transcripts from the human reference (from fasta, transcript annotation and transcript length files.)\n",
    "\n",
    "  * MTRNR2L1-201  \n",
    "  * MTRNR2L10-201   \n",
    "  * MTRNR2L11-201  \n",
    "  * MTRNR2L12-201 \n",
    "  * MTRNR2L13-201\n",
    "  * MTRNR2L3-201    \n",
    "  * MTRNR2L4-201  \n",
    "  * MTRNR2L5-201   \n",
    "  * MTRNR2L6-201  \n",
    "  * MTRNR2L7-201  \n",
    "  * MTRNR2L8-201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1902a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9fb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastaEntry:\n",
    "    '''\n",
    "    Given a header and a sequence, creates a fasta entry.\n",
    "    The string representation of the fasta entry consists\n",
    "    of 50 nts per line.\n",
    "    Do not change the chunk size (= 50)\n",
    "    TODO : Consider making header and sequence properties\n",
    "    Also consider putting more checks here for the input\n",
    "    '''\n",
    "    def __init__(self , header , sequence ):\n",
    "        self.header   = header\n",
    "        self.sequence = sequence\n",
    "\n",
    "    def reverse_complement(self):\n",
    "        complements = {\"A\" : \"T\" , \"a\" : \"t\" ,\n",
    "                   \"C\" : \"G\" , \"c\" : \"g\" ,\n",
    "                   \"G\" : \"C\" , \"g\" : \"c\" ,\n",
    "                   \"T\" : \"A\" , \"t\" : \"a\" ,\n",
    "                   \"N\" : \"N\" , \"n\" : \"n\"}\n",
    "        result = list()\n",
    "\n",
    "        for i in range(len(self.sequence) - 1 , -1 , -1 ):\n",
    "            try:\n",
    "                result.append(complements[self.sequence[i]])\n",
    "            except IndexError:\n",
    "                error_message = \"Invalid character (%s) in the fasta sequence with header \\n\" \\\n",
    "                                \"%s\"%(self.sequence[i] , self.header)\n",
    "                raise IOError(error_message)\n",
    "        self.sequence = \"\".join(result)\n",
    "\n",
    "\n",
    "    def __str__(self ):\n",
    "        chunk_size                  = 50 # Do not change this!\n",
    "        result_list                 = [ '>' +  self.header ]\n",
    "        sequence_size               = len(self.sequence)\n",
    "        number_of_remaining_letters = sequence_size\n",
    "        number_of_processed_letters = 0\n",
    "\n",
    "        while number_of_remaining_letters > 0:\n",
    "            if number_of_remaining_letters <= chunk_size:\n",
    "                result_list.append(self.sequence[ number_of_processed_letters : ])\n",
    "                number_of_remaining_letters = 0\n",
    "                number_of_processed_letters = sequence_size\n",
    "            else:\n",
    "                new_number_of_processed_letters = number_of_processed_letters + chunk_size\n",
    "                result_list.append(self.sequence[ number_of_processed_letters : new_number_of_processed_letters])\n",
    "                number_of_remaining_letters -= chunk_size\n",
    "                number_of_processed_letters  = new_number_of_processed_letters\n",
    "\n",
    "        return(\"\\n\".join( result_list ) )\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "class FastaFile:\n",
    "    '''\n",
    "    This object is used to read fasta files into FastaEntry objects.\n",
    "    For writing fasta files, we only need FastaEntry objects and using\n",
    "    their str function, we can convert them to string and write to files.\n",
    "    Note that it can be used as a context manager as well.\n",
    "    '''\n",
    "\n",
    "    def __init__(self , file):\n",
    "        myopen = open\n",
    "        if file.endswith(\".gz\"):\n",
    "            myopen = gzip.open\n",
    "\n",
    "        if(file):\n",
    "            self.f = myopen(file , \"rt\")\n",
    "        else:\n",
    "            self.f = stdin\n",
    "\n",
    "        self.current_header = \"\"\n",
    "        self.current_sequence = list()\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "\n",
    "\n",
    "    ######################################################\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        for raw_line in self.f:\n",
    "            line = raw_line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line[0] == \">\":\n",
    "                if not self.current_header:\n",
    "                    self.current_header = (line[1:].split())[0]\n",
    "                    self.current_sequence = list()\n",
    "                else:\n",
    "                    this_entry = FastaEntry(header = self.current_header , sequence = \"\".join(self.current_sequence) )\n",
    "                    self.current_header = (line[1:].split())[0]\n",
    "                    self.current_sequence = list()\n",
    "                    return(this_entry)\n",
    "            else:\n",
    "                self.current_sequence.append(line)\n",
    "\n",
    "        # this returns the last entry\n",
    "        if len(self.current_sequence) > 0:\n",
    "            this_entry = FastaEntry(header = self.current_header , sequence = \"\".join(self.current_sequence) )\n",
    "            self.current_sequence = list()\n",
    "            return(this_entry)\n",
    "\n",
    "        raise IndexError\n",
    "\n",
    "    #########################################################\n",
    "\n",
    "    def __del__(self):\n",
    "        self.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7ac58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f0b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a163107",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_to_be_removed = [\\\n",
    "    \"MTRNR2L1-201\", \n",
    "    \"MTRNR2L10-201\", \n",
    "    \"MTRNR2L11-201\", \n",
    "    \"MTRNR2L12-201\", \n",
    "    \"MTRNR2L13-201\",\n",
    "    \"MTRNR2L3-201\",  \n",
    "    \"MTRNR2L4-201\",  \n",
    "    \"MTRNR2L5-201\",  \n",
    "    \"MTRNR2L6-201\",  \n",
    "    \"MTRNR2L7-201\", \n",
    "    \"MTRNR2L8-201\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bdd767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dea870e",
   "metadata": {},
   "source": [
    "## Fasta File "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d4044",
   "metadata": {},
   "source": [
    "First we list the transcripts that we will exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca148932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENST00000604646.1|ENSG00000270188.1|OTTHUMG00000184992.1|OTTHUMT00000469412.1|MTRNR2L11-201|MTRNR2L11|1552|UTR5:1-949|CDS:950-1024|UTR3:1025-1552|\n",
      "ENST00000600213.3|ENSG00000269028.3|OTTHUMG00000175726.3|OTTHUMT00000430905.3|MTRNR2L12-201|MTRNR2L12|1049|UTR5:1-963|CDS:964-1038|UTR3:1039-1049|\n",
      "ENST00000604093.2|ENSG00000270394.4|OTTHUMG00000184994.3|OTTHUMT00000469414.3|MTRNR2L13-201|MTRNR2L13|1445|UTR5:1-925|CDS:926-1000|UTR3:1001-1445|\n",
      "ENST00000604952.1|ENSG00000270672.1|OTTHUMG00000184977.2|OTTHUMT00000469394.2|MTRNR2L6-201|MTRNR2L6|1447|UTR5:1-959|CDS:960-1034|UTR3:1035-1447|\n",
      "ENST00000544824.2|ENSG00000256892.2|OTTHUMG00000184979.1|OTTHUMT00000469397.1|MTRNR2L7-201|MTRNR2L7|1535|UTR5:1-930|CDS:931-1005|UTR3:1006-1535|\n",
      "ENST00000512524.4|ENSG00000249860.4|OTTHUMG00000184965.2|OTTHUMT00000469382.2|MTRNR2L5-201|MTRNR2L5|1687|UTR5:1-858|CDS:859-933|UTR3:934-1687|\n",
      "ENST00000536684.3|ENSG00000255823.5|OTTHUMG00000184980.2|OTTHUMT00000469398.2|MTRNR2L8-201|MTRNR2L8|1293|UTR5:1-960|CDS:961-1035|UTR3:1036-1293|\n",
      "ENST00000399974.5|ENSG00000232196.4|OTTHUMG00000184964.3|OTTHUMT00000469381.3|MTRNR2L4-201|MTRNR2L4|1690|UTR5:1-766|CDS:767-853|UTR3:854-1690|\n",
      "ENST00000540040.2|ENSG00000256618.2|OTTHUMG00000179068.2|OTTHUMT00000444600.2|MTRNR2L1-201|MTRNR2L1|1553|UTR5:1-951|CDS:952-1026|UTR3:1027-1553|\n",
      "ENST00000543500.3|ENSG00000256222.3|OTTHUMG00000184962.3|OTTHUMT00000469379.3|MTRNR2L3-201|MTRNR2L3|1052|UTR5:1-459|CDS:460-534|UTR3:535-1052|\n",
      "ENST00000545075.3|ENSG00000256045.3|OTTHUMG00000184991.3|OTTHUMT00000469411.3|MTRNR2L10-201|MTRNR2L10|1051|UTR5:1-448|CDS:449-523|UTR3:524-1051|\n"
     ]
    }
   ],
   "source": [
    "input_fasta_path  = \"../transcriptome_old_v2/appris_human_v2_selected.fa.gz\"\n",
    "output_fasta_path = \"appris_human_v2_after_filtering.fa.gz\"\n",
    "\n",
    "input_fasta = FastaFile(input_fasta_path)\n",
    "\n",
    "for e in input_fasta:\n",
    "    header_contents = e.header.split(\"|\")\n",
    "    \n",
    "    if header_contents[4].find(\"MTRNR2L\") >= 0:\n",
    "        print(e.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51c26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fasta = FastaFile(input_fasta_path)\n",
    "\n",
    "with gzip.open(output_fasta_path, \"wt\") as output_stream:\n",
    "    for e in input_fasta:\n",
    "        header_contents = e.header.split(\"|\")\n",
    "\n",
    "        if header_contents[4].find(\"MTRNR2L\") < 0:\n",
    "            print(e, file = output_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd9e5d",
   "metadata": {},
   "source": [
    "Now let's name sure that the output doesn't contain MTRNR2L transcripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd970e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fasta = FastaFile(output_fasta_path)\n",
    "\n",
    "for e in output_fasta:\n",
    "    header_contents = e.header.split(\"|\")\n",
    "    \n",
    "    if header_contents[4].find(\"MTRNR2L\") >= 0:\n",
    "        print(e.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8453d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214290bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c83b90d",
   "metadata": {},
   "source": [
    "## Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a887d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_annotation_file = \"../transcriptome_old_v2/appris_human_v2_actual_regions.bed\"\n",
    "new_annotation_file = \"appris_human_v2_after_filtering_regions.bed\"\n",
    "\n",
    "with open(old_annotation_file, \"rt\") as input_stream,\\\n",
    "     open(new_annotation_file, \"wt\") as output_stream:\n",
    "    for this_line in input_stream:\n",
    "        contents = this_line.split()\n",
    "        \n",
    "        if len(contents) < 5:\n",
    "            continue\n",
    "        \n",
    "        if contents[0].find(\"MTRNR2L\") < 0:\n",
    "            print(this_line, file=output_stream, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "784137b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep MTRNR2L appris_human_v2_after_filtering_regions.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf5fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca4b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07becc79",
   "metadata": {},
   "source": [
    "## Lengths File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3962ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lengths_file = \"../transcriptome_old_v2/appris_human_v2_transcript_lengths.tsv\"\n",
    "new_lengths_file = \"appris_human_v2_after_filtering_t_lengths.tsv\"\n",
    "\n",
    "\n",
    "with open(old_lengths_file, \"rt\") as input_stream,\\\n",
    "     open(new_lengths_file, \"wt\") as output_stream:\n",
    "    for this_line in input_stream:\n",
    "        contents = this_line.split()\n",
    "        \n",
    "        if len(contents) < 2:\n",
    "            continue\n",
    "        \n",
    "        if contents[0].find(\"MTRNR2L\") < 0:\n",
    "            print(this_line, file=output_stream, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14435eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6515516",
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep MTRNR2L appris_human_v2_after_filtering_t_lengths.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
